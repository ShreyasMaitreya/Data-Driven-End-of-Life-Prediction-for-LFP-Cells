#getting this error: RuntimeError: size mismatch, m1: [1 x 2201], m2: [1 x 1] at ..\aten\src\TH/generic/THTensorMath.cpp:41 will find out about this....
import torch as pt
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as graph

#this code is made considering constant i.e. temperature = 303K
#Nominal voltage of cell is 3.3V, charged in CC-CV at 1C current and discharged at 4C
#reference paper Severson et al. Data-driven prediction of battery cycle life before capacity degradation. Nature Energy volume 4, pages 383â€“391 (2019).
#current focus is on Lithium Iron Phosphate type of battery (LFP chemistry, but code can work for any chemistry and any on a battery pack of any size)
#dataset has been taken from https://data.matr.io/1
x = np.linspace(1, 2201, num = 2201) #easier to define linspace vector using numpy
N = pt.from_numpy(x.astype(np.double))    #conversion of numpy array to pytorch tensor
N = N.float()
SOH_actual = pt.tensor([100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,99.98,99.96,99.96,99.96,99.95,99.93,99.93,99.93,99.92,99.91,99.9,99.89,99.88,99.86,99.83,99.83,99.82,99.81,99.81,99.8,99.8,99.79,99.76,99.75,99.75,99.73,99.73,99.72,99.7,99.7,99.68,99.64,99.63,99.61,99.61,99.6,99.6,99.6,99.59,99.59,99.58,99.57,99.57,99.56,99.56,99.55,99.55,99.55,99.54,99.52,99.5,99.5,99.49,99.45,99.44,99.44,99.43,99.4,99.37,99.36,99.34,99.34,99.32,99.32,99.3,99.29,99.26,99.25,99.24,99.24,99.23,99.2,99.19,99.17,99.16,99.16,99.14,99.13,99.13,99.12,99.11,99.11,99.11,99.09,99.08,99.07,99.06,99.05,99.04,99.03,99.02,99,98.98,98.98,98.97,98.95,98.92,98.91,98.9,98.87,98.83,98.82,98.82,98.82,98.8,98.8,98.8,98.77,98.77,98.75,98.74,98.73,98.72,98.72,98.71,98.7,98.69,98.69,98.67,98.67,98.66,98.66,98.63,98.61,98.59,98.58,98.57,98.57,98.56,98.55,98.51,98.5,98.49,98.48,98.47,98.47,98.43,98.43,98.4,98.39,98.36,98.36,98.36,98.35,98.34,98.33,98.32,98.32,98.31,98.28,98.28,98.26,98.26,98.26,98.24,98.24,98.22,98.22,98.21,98.2,98.2,98.19,98.19,98.15,98.14,98.13,98.11,98.09,98.08,98.06,98.05,98.04,98.02,97.98,97.98,97.98,97.97,97.96,97.96,97.95,97.92,97.92,97.92,97.91,97.88,97.87,97.86,97.86,97.85,97.84,97.83,97.82,97.79,97.79,97.78,97.77,97.76,97.76,97.75,97.74,97.74,97.71,97.7,97.7,97.68,97.68,97.65,97.65,97.64,97.61,97.61,97.59,97.57,97.55,97.55,97.54,97.52,97.51,97.5,97.49,97.49,97.46,97.45,97.43,97.42,97.42,97.42,97.41,97.41,97.39,97.38,97.36,97.35,97.33,97.33,97.33,97.32,97.3,97.29,97.29,97.27,97.26,97.22,97.2,97.2,97.2,97.18,97.16,97.16,97.15,97.14,97.14,97.14,97.12,97.12,97.1,97.1,97.08,97.07,97.06,97.05,97.03,97.01,97,97,96.98,96.97,96.97,96.95,96.92,96.91,96.9,96.89,96.88,96.87,96.87,96.87,96.86,96.86,96.85,96.83,96.8,96.79,96.77,96.76,96.76,96.75,96.75,96.74,96.7,96.7,96.69,96.66,96.66,96.65,96.65,96.64,96.64,96.6,96.6,96.59,96.58,96.57,96.55,96.55,96.55,96.55,96.54,96.53,96.5,96.49,96.46,96.43,96.43,96.43,96.43,96.42,96.42,96.38,96.37,96.34,96.34,96.34,96.34,96.33,96.32,96.32,96.3,96.3,96.29,96.29,96.24,96.24,96.23,96.22,96.22,96.2,96.2,96.17,96.16,96.16,96.13,96.13,96.11,96.1,96.09,96.09,96.08,96.04,96.01,96.01,96.01,96,95.98,95.98,95.98,95.97,95.97,95.94,95.94,95.93,95.92,95.91,95.9,95.89,95.88,95.88,95.86,95.86,95.82,95.82,95.8,95.79,95.79,95.78,95.77,95.76,95.75,95.75,95.74,95.72,95.72,95.71,95.7,95.69,95.65,95.64,95.64,95.6,95.6,95.59,95.57,95.56,95.55,95.53,95.52,95.52,95.52,95.51,95.51,95.5,95.5,95.49,95.47,95.44,95.43,95.43,95.42,95.41,95.4,95.4,95.39,95.39,95.38,95.36,95.35,95.34,95.33,95.32,95.31,95.31,95.3,95.3,95.22,95.22,95.22,95.22,95.21,95.21,95.21,95.19,95.15,95.15,95.15,95.14,95.13,95.12,95.11,95.1,95.09,95.08,95.06,95.03,95.02,95.02,95.02,95.01,95.01,95.01,94.99,94.99,94.98,94.97,94.96,94.95,94.94,94.93,94.93,94.92,94.89,94.88,94.86,94.85,94.84,94.83,94.83,94.81,94.8,94.8,94.8,94.77,94.75,94.75,94.74,94.72,94.72,94.7,94.69,94.68,94.68,94.66,94.65,94.64,94.63,94.63,94.61,94.6,94.6,94.59,94.59,94.59,94.58,94.56,94.56,94.55,94.53,94.53,94.53,94.51,94.48,94.48,94.46,94.46,94.46,94.44,94.43,94.41,94.41,94.41,94.38,94.38,94.35,94.34,94.33,94.33,94.32,94.3,94.29,94.28,94.28,94.28,94.26,94.24,94.22,94.22,94.19,94.19,94.18,94.17,94.17,94.16,94.16,94.15,94.14,94.14,94.13,94.13,94.12,94.12,94.09,94.09,94.09,94.07,94.06,94.06,94.04,94.03,94.03,94.01,93.99,93.98,93.97,93.95,93.94,93.93,93.93,93.93,93.92,93.9,93.89,93.88,93.84,93.84,93.83,93.83,93.82,93.8,93.78,93.78,93.77,93.76,93.76,93.74,93.73,93.73,93.72,93.72,93.71,93.7,93.7,93.69,93.65,93.65,93.65,93.65,93.65,93.63,93.61,93.61,93.59,93.59,93.57,93.54,93.54,93.54,93.54,93.54,93.53,93.52,93.51,93.48,93.46,93.46,93.46,93.46,93.45,93.41,93.41,93.4,93.37,93.37,93.36,93.34,93.34,93.33,93.33,93.32,93.31,93.3,93.29,93.29,93.28,93.28,93.27,93.27,93.24,93.23,93.22,93.2,93.18,93.17,93.17,93.17,93.15,93.15,93.14,93.14,93.13,93.13,93.11,93.1,93.09,93.08,93.06,93.05,93.03,93.03,93.03,92.99,92.97,92.97,92.97,92.95,92.95,92.95,92.94,92.93,92.93,92.92,92.9,92.89,92.89,92.87,92.87,92.86,92.85,92.84,92.81,92.8,92.79,92.78,92.78,92.77,92.77,92.76,92.76,92.75,92.74,92.73,92.72,92.71,92.71,92.7,92.69,92.66,92.64,92.64,92.62,92.61,92.61,92.61,92.57,92.57,92.57,92.55,92.54,92.53,92.53,92.52,92.51,92.51,92.51,92.48,92.47,92.45,92.44,92.43,92.43,92.39,92.38,92.37,92.37,92.37,92.36,92.35,92.34,92.34,92.34,92.33,92.33,92.32,92.31,92.3,92.29,92.28,92.27,92.25,92.25,92.25,92.22,92.2,92.19,92.19,92.18,92.17,92.17,92.16,92.13,92.13,92.13,92.11,92.1,92.09,92.09,92.07,92.06,92.03,92.02,92.01,92.01,92,92,91.98,91.98,91.97,91.96,91.94,91.94,91.94,91.93,91.92,91.89,91.89,91.88,91.85,91.84,91.83,91.83,91.83,91.82,91.81,91.79,91.79,91.79,91.79,91.77,91.76,91.76,91.75,91.74,91.74,91.73,91.71,91.69,91.68,91.66,91.66,91.64,91.64,91.62,91.61,91.61,91.6,91.59,91.56,91.56,91.56,91.54,91.54,91.53,91.51,91.5,91.49,91.49,91.48,91.47,91.46,91.46,91.45,91.44,91.43,91.4,91.4,91.39,91.37,91.36,91.36,91.35,91.34,91.32,91.32,91.32,91.31,91.3,91.28,91.27,91.27,91.27,91.26,91.24,91.24,91.2,91.17,91.17,91.17,91.17,91.16,91.15,91.14,91.14,91.14,91.14,91.1,91.1,91.09,91.08,91.06,91.03,91.03,91.03,91.01,90.99,90.99,90.99,90.98,90.98,90.97,90.96,90.96,90.95,90.94,90.94,90.93,90.93,90.9,90.9,90.87,90.86,90.84,90.81,90.81,90.8,90.8,90.79,90.79,90.76,90.76,90.76,90.76,90.76,90.75,90.75,90.73,90.72,90.71,90.69,90.63,90.63,90.62,90.61,90.61,90.61,90.6,90.6,90.59,90.58,90.58,90.56,90.56,90.55,90.54,90.53,90.53,90.51,90.49,90.48,90.47,90.46,90.45,90.44,90.42,90.42,90.42,90.42,90.42,90.41,90.4,90.39,90.36,90.35,90.34,90.34,90.32,90.32,90.29,90.27,90.26,90.25,90.25,90.24,90.23,90.22,90.22,90.21,90.21,90.17,90.16,90.16,90.16,90.15,90.14,90.14,90.12,90.12,90.09,90.08,90.08,90.08,90.05,90.03,90.03,90.02,90.02,90,89.98,89.97,89.96,89.96,89.95,89.95,89.95,89.95,89.93,89.93,89.91,89.91,89.91,89.91,89.89,89.86,89.85,89.84,89.84,89.79,89.78,89.78,89.77,89.76,89.76,89.74,89.74,89.73,89.73,89.73,89.73,89.69,89.69,89.68,89.67,89.65,89.65,89.64,89.61,89.61,89.6,89.59,89.58,89.57,89.56,89.56,89.56,89.56,89.56,89.54,89.49,89.47,89.47,89.46,89.46,89.45,89.43,89.43,89.42,89.42,89.41,89.41,89.41,89.4,89.38,89.36,89.36,89.36,89.34,89.31,89.3,89.3,89.28,89.27,89.26,89.25,89.24,89.23,89.22,89.22,89.22,89.22,89.21,89.18,89.17,89.16,89.16,89.15,89.15,89.12,89.1,89.09,89.09,89.08,89.06,89.06,89.05,89.05,89.04,89.04,89.04,89.03,89,89,88.97,88.95,88.93,88.92,88.92,88.91,88.89,88.89,88.88,88.88,88.88,88.86,88.86,88.86,88.86,88.86,88.85,88.82,88.77,88.76,88.75,88.75,88.75,88.74,88.72,88.72,88.72,88.71,88.7,88.68,88.68,88.67,88.67,88.66,88.66,88.65,88.64,88.62,88.6,88.58,88.57,88.56,88.55,88.55,88.55,88.54,88.54,88.51,88.51,88.49,88.49,88.48,88.47,88.47,88.46,88.42,88.41,88.4,88.38,88.38,88.37,88.37,88.35,88.35,88.35,88.33,88.32,88.31,88.31,88.3,88.3,88.29,88.28,88.28,88.24,88.21,88.19,88.19,88.19,88.18,88.17,88.16,88.16,88.15,88.15,88.14,88.13,88.13,88.12,88.11,88.1,88.09,88.09,88.08,88.07,88.06,88.04,88.04,88.04,88,87.99,87.98,87.98,87.98,87.95,87.94,87.94,87.94,87.92,87.92,87.89,87.89,87.89,87.88,87.87,87.87,87.85,87.85,87.82,87.82,87.81,87.8,87.79,87.76,87.76,87.76,87.75,87.75,87.74,87.73,87.73,87.72,87.72,87.69,87.69,87.68,87.64,87.64,87.63,87.63,87.62,87.61,87.6,87.59,87.57,87.57,87.57,87.56,87.56,87.55,87.55,87.55,87.55,87.55,87.54,87.52,87.51,87.5,87.47,87.46,87.45,87.45,87.44,87.4,87.39,87.39,87.39,87.39,87.38,87.37,87.37,87.36,87.35,87.35,87.34,87.34,87.31,87.3,87.3,87.28,87.28,87.27,87.27,87.24,87.21,87.21,87.2,87.2,87.2,87.19,87.19,87.18,87.18,87.17,87.15,87.15,87.14,87.14,87.11,87.11,87.11,87.11,87.08,87.06,87.06,87.04,87.04,87.03,87.02,87.01,87.01,87.01,87.01,87,87,87,86.99,86.95,86.95,86.94,86.93,86.93,86.92,86.89,86.89,86.88,86.88,86.87,86.87,86.87,86.84,86.84,86.83,86.83,86.83,86.81,86.81,86.8,86.8,86.78,86.77,86.76,86.76,86.73,86.72,86.71,86.7,86.69,86.68,86.67,86.67,86.66,86.66,86.65,86.65,86.65,86.65,86.65,86.62,86.62,86.61,86.58,86.58,86.57,86.56,86.53,86.53,86.53,86.52,86.51,86.51,86.49,86.49,86.48,86.48,86.47,86.47,86.47,86.44,86.43,86.43,86.43,86.41,86.41,86.4,86.36,86.36,86.35,86.35,86.35,86.34,86.34,86.33,86.32,86.31,86.31,86.3,86.29,86.28,86.27,86.25,86.25,86.24,86.24,86.23,86.22,86.22,86.2,86.18,86.16,86.16,86.15,86.15,86.15,86.14,86.14,86.14,86.13,86.11,86.1,86.1,86.09,86.06,86.06,86.06,86.06,86.03,86.02,86.01,86.01,86,85.99,85.98,85.98,85.97,85.96,85.96,85.95,85.93,85.92,85.91,85.91,85.91,85.88,85.88,85.88,85.87,85.87,85.84,85.83,85.82,85.81,85.8,85.79,85.79,85.78,85.78,85.76,85.76,85.76,85.75,85.75,85.74,85.73,85.73,85.71,85.71,85.7,85.69,85.69,85.67,85.67,85.66,85.64,85.63,85.62,85.61,85.61,85.59,85.57,85.57,85.56,85.56,85.56,85.55,85.55,85.55,85.53,85.5,85.5,85.5,85.5,85.49,85.46,85.46,85.45,85.44,85.43,85.42,85.42,85.41,85.41,85.38,85.38,85.38,85.37,85.37,85.36,85.36,85.33,85.33,85.32,85.31,85.28,85.28,85.28,85.26,85.26,85.26,85.25,85.25,85.24,85.24,85.23,85.2,85.2,85.18,85.18,85.18,85.18,85.17,85.17,85.16,85.13,85.13,85.12,85.12,85.11,85.11,85.11,85.06,85.06,85.06,85.05,85.04,85.02,85.01,85.01,85,85,84.99,84.98,84.98,84.97,84.96,84.95,84.94,84.94,84.94,84.94,84.93,84.89,84.88,84.86,84.86,84.84,84.83,84.83,84.83,84.83,84.83,84.83,84.81,84.81,84.79,84.79,84.77,84.76,84.76,84.76,84.75,84.74,84.7,84.69,84.68,84.67,84.66,84.66,84.66,84.65,84.65,84.65,84.64,84.63,84.62,84.61,84.6,84.59,84.59,84.58,84.58,84.57,84.57,84.57,84.52,84.52,84.5,84.5,84.49,84.48,84.47,84.47,84.47,84.46,84.45,84.44,84.44,84.42,84.42,84.42,84.41,84.41,84.41,84.39,84.39,84.38,84.38,84.34,84.32,84.32,84.31,84.3,84.29,84.28,84.28,84.26,84.25,84.24,84.24,84.23,84.22,84.21,84.21,84.2,84.2,84.2,84.19,84.19,84.18,84.16,84.15,84.13,84.13,84.13,84.11,84.1,84.08,84.08,84.08,84.08,84.07,84.04,84.02,84.01,84.01,84.01,83.99,83.99,83.99,83.98,83.98,83.97,83.97,83.97,83.96,83.96,83.96,83.95,83.92,83.92,83.91,83.9,83.89,83.89,83.85,83.83,83.83,83.82,83.79,83.79,83.79,83.79,83.78,83.78,83.77,83.76,83.76,83.74,83.74,83.74,83.74,83.73,83.73,83.73,83.72,83.71,83.7,83.64,83.64,83.64,83.64,83.61,83.61,83.61,83.6,83.59,83.59,83.57,83.57,83.57,83.56,83.55,83.55,83.54,83.53,83.53,83.52,83.52,83.5,83.49,83.49,83.45,83.45,83.45,83.44,83.43,83.43,83.41,83.4,83.4,83.39,83.38,83.37,83.37,83.37,83.34,83.34,83.33,83.33,83.33,83.32,83.31,83.28,83.27,83.27,83.27,83.26,83.25,83.25,83.25,83.24,83.23,83.23,83.21,83.21,83.2,83.19,83.19,83.18,83.16,83.15,83.12,83.11,83.1,83.09,83.09,83.08,83.08,83.08,83.08,83.07,83.07,83.06,83.05,83.04,83.01,83.01,83,83,82.99,82.98,82.98,82.94,82.92,82.91,82.91,82.91,82.91,82.9,82.9,82.89,82.89,82.89,82.89,82.88,82.88,82.87,82.87,82.83,82.82,82.81,82.8,82.8,82.79,82.78,82.78,82.78,82.77,82.77,82.74,82.74,82.73,82.73,82.72,82.71,82.71,82.71,82.7,82.68,82.67,82.65,82.65,82.64,82.64,82.64,82.63,82.62,82.62,82.61,82.61,82.59,82.58,82.57,82.54,82.54,82.53,82.53,82.52,82.52,82.5,82.49,82.49,82.48,82.47,82.46,82.45,82.45,82.45,82.44,82.44,82.43,82.42,82.42,82.41,82.4,82.39,82.37,82.36,82.35,82.35,82.35,82.34,82.34,82.33,82.31,82.3,82.3,82.3,82.28,82.26,82.26,82.25,82.24,82.22,82.22,82.22,82.21,82.19,82.18,82.18,82.17,82.17,82.17,82.15,82.15,82.14,82.1,82.1,82.1,82.09,82.08,82.07,82.06,82.05,82.02,82,82,82,81.99,81.99,81.99,81.96,81.96,81.95,81.95,81.94,81.92,81.92,81.91,81.91,81.91,81.9,81.9,81.89,81.88,81.84,81.83,81.83,81.82,81.81,81.78,81.78,81.77,81.75,81.75,81.74,81.72,81.72,81.71,81.71,81.66,81.65,81.63,81.63,81.63,81.62,81.61,81.59,81.59,81.58,81.57,81.56,81.55,81.54,81.54,81.53,81.53,81.51,81.49,81.48,81.47,81.46,81.46,81.44,81.44,81.44,81.41,81.4,81.38,81.36,81.35,81.35,81.35,81.35,81.34,81.33,81.29,81.28,81.28,81.27,81.26,81.26,81.25,81.23,81.23,81.2,81.2,81.19,81.19,81.17,81.16,81.12,81.11,81.1,81.09,81.08,81.07,81.05,81.05,81.05,81.03,81.03,81.02]).float()
print(x)
SOH = SOH_actual.numpy()
N_test = pt.tensor([2201], dtype = pt.double) 

n_samples = 2201
n_features = 1
print(n_samples, n_features)

#model (linear regression)
input_size = 1
output_size = n_features
model = nn.Linear(input_size, output_size)


#loss and optimizer, calculation of cost function
learning_rate  = 0.01
criterion = nn.MSELoss()
optimizer = pt.optim.SGD(model.parameters(), lr = learning_rate)

#training loop
num_epochs = 100
for epoch in range(num_epochs):
    SOH_predicted = model(N.float())
    loss = criterion(SOH_predicted,SOH_actual)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
    
    if (epoch+1)%10 == 0:
        print (f'epoch: {epoch+1}, loss = {loss.item():.4f}')
#graph
predicted = model(N).detach().numpy() #matplotlib only takes numpy arrays
graph.plot(x, SOH, 'ro')#ro means red dots
graph.plot(x, predicted, 'b')
graph.show()
